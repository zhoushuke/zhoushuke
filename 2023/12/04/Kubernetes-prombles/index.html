<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Kubernetes," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头 不定期更新">
<meta property="og:type" content="article">
<meta property="og:title" content="Kubernetes学习(Kubernetes踩坑记)">
<meta property="og:url" content="https://zhoushuke.github.io/2023/12/04/Kubernetes-prombles/index.html">
<meta property="og:site_name" content="Z.S.K.&#39;s Records">
<meta property="og:description" content="记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头 不定期更新">
<meta property="og:locale">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20220106144313.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20211118152201.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210622102036.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210428190009.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210307212429.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/image-20210302200255132.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210106185555.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201223232538.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201223233150.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201112171302.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201017221807.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200909154834.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200908211841.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902132758.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902123531.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200901183122.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902101139.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200827183609.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200827184435.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430132115.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430132148.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/41B2684F-312C-41ED-AF56-D6014C6B74E6.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430145913.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/63611F8A-F803-46F5-8792-67111E03DF91.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/FB66ABBE-FF79-48A4-8A8B-7FDC3AED6634.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/ACEB6BE6-7E22-4A43-AB4A-A51E00CE9EFE.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/5FECFF57-F204-4ADF-A9E0-5F1D9A917194.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/447313AF-7DD6-4FB4-8F46-AE1DC468C7CA.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/C73EB07F-14CD-43A7-86C0-49B4812F57A6.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/2AE46262-2624-446C-909E-1FA0E76A8AD7.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506115705.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506115805.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506120151.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506120040.png">
<meta property="og:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200511180743.png">
<meta property="article:published_time" content="2023-12-04T11:30:53.000Z">
<meta property="article:modified_time" content="2024-08-16T05:32:46.155Z">
<meta property="article:author" content="Z.S.K.">
<meta property="article:tag" content="Kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zhoushuke.github.io/2023/12/04/Kubernetes-prombles/"/>





  <title> Kubernetes学习(Kubernetes踩坑记) | Z.S.K.'s Records </title>
<meta name="generator" content="Hexo 6.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Z.S.K.'s Records</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/ZSK-Profile.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            简历
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="https://zhoushuke.github.io/2023/12/04/Kubernetes-prombles/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Z.S.K.'s Records">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Z.S.K.'s Records" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Kubernetes学习(Kubernetes踩坑记)
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-12-04T19:30:53+08:00">
                2023-12-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kubernetes/" itemprop="url" rel="index">
                    <span itemprop="name">Kubernetes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>记录在使用Kubernetes中遇到的各种问题及解决方案, 好记性不如烂笔头</p>
<p><strong>不定期更新</strong></p>
<span id="more"></span>

<h3 id="kubelet日志错误-Unable-to-create-endpoint-status-429"><a href="#kubelet日志错误-Unable-to-create-endpoint-status-429" class="headerlink" title="kubelet日志错误: Unable to create endpoint (status 429)"></a>kubelet日志错误: Unable to create endpoint (status 429)</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unable to create endpoint: response status code does not match any response statuses defined <span class="keyword">for</span> this endpoint <span class="keyword">in</span> the swagger spec (status 429)</span><br></pre></td></tr></table></figure>

<p>原因: 并发创建的pod数太多触发了cilium的api-rate-limit配置上限, 更详细的说明可参考以下链接<br>解决: 参考<a target="_blank" rel="noopener" href="https://izsk.me/2024/08/10/cilium-on-kubernetes-errors-apiratelimit/">cilium在kubernetes中的生产实践六(cilium排错指南)之api-rate-limit</a></p>
<h3 id="kubelet中提示-no-relationship-found-between-node-xxx-and-this-object"><a href="#kubelet中提示-no-relationship-found-between-node-xxx-and-this-object" class="headerlink" title="kubelet中提示: no relationship found between node xxx and this object"></a>kubelet中提示: no relationship found between node xxx and this object</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">User <span class="string">&quot;system:node:xxx&quot;</span> cannot list resource <span class="string">&quot;configmap&quot;</span> <span class="keyword">in</span> API group <span class="keyword">in</span> the namespace <span class="string">&quot;xxx&quot;</span>, no relationship found between node xxx and this object</span><br></pre></td></tr></table></figure>

<p>原因: 由于集群开启了Node Authorization Mode,所以节点上的kubelet能操作的权限是跟节点上运行pod相关联的，可以通过以下的方式验证</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录到节点kubectl</span></span><br><span class="line">kubectl --kubeconfig=/etc/kubernetes/kubelet.conf -n xxx can-i list cm/xxx</span><br><span class="line"><span class="comment"># 如果有权限则提示yes, 没有则为no</span></span><br></pre></td></tr></table></figure>

<p>解决:  如果需要访问，则可通过一个pod挂载对应的cm调度到该节点上，那么在这个node上即可通过kubelet访问到相关的cm</p>
<p>参考:  </p>
<ol>
<li><p><a target="_blank" rel="noopener" href="https://enix.io/fr/blog/kubernetes-tip-and-tricks-node-authorization-mode/">Kubernetes : Le Node Authorization Mode de l&#39;API-Server</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.frognew.com/2021/05/k8s-apiserver-authorization-mode-node.html">kubernetes apiserver的node鉴权 | 青蛙小白</a></p>
</li>
</ol>
<h3 id="kube-controller-manager日志出现-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1"><a href="#kube-controller-manager日志出现-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1" class="headerlink" title="kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1"></a>kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1</h3><p>原因: apiservice存在Failed的service</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get apiservice</span><br><span class="line"><span class="comment"># 查看是否存在ServiceNotFound, 删除对应的service即可</span></span><br><span class="line">kubectl delete apiservice &#123;name&#125;</span><br></pre></td></tr></table></figure>

<h3 id="kubelet启动时提示Failed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id"><a href="#kubelet启动时提示Failed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id" class="headerlink" title="kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id"></a>kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id</h3><p>原因: kubelet的数据目录存在脏容器数据</p>
<p>解决: 使用以下命令找到脏容器，删除后重启kubelet</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 894f35dca3eda57adef28b69acd0607efdeb34e8814e87e196bc163305576028 是上面报错中的ID</span></span><br><span class="line">docker ps -a --filter <span class="string">&quot;label=io.kubernetes.sandbox.id=894f35dca3eda57adef28b69acd0607efdeb34e8814e87e196bc163305576028&quot;</span></span><br><span class="line"><span class="comment"># 根据上述ID删除容器</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">rm</span> ID</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启kubelet</span></span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure>

<h3 id="prometheus-logs-compaction-failed-对数的性质uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page"><a href="#prometheus-logs-compaction-failed-对数的性质uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page" class="headerlink" title="prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page"></a>prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page</h3><p>原因: prometheus在对wal进行压缩时出现segment错误，导致创建checkout失败</p>
<p>解决: 在prometheus持久化目录下删除上述xxxx的目录，然后重启prometheus</p>
<p>重启后可能会出现unexpected gap to last checkpoint, expect: xxx, requested: yyy</p>
<p>需要将checkout目录也进行删除，然后重启prometheus实例 </p>
<h3 id="is-forbidden-User-xxx-cannot-get-resource-“services-x2F-proxy”"><a href="#is-forbidden-User-xxx-cannot-get-resource-“services-x2F-proxy”" class="headerlink" title="is forbidden: User xxx cannot get resource “services&#x2F;proxy”"></a>is forbidden: User xxx cannot get resource “services&#x2F;proxy”</h3><p>在rancher中使用非admin用户无法显示grafana的 workload metrics, 请求中提示: services http:rancher-monitoring-grafana:80 is forbidden: User xxx cannot get resource “services&#x2F;proxy” in API group “” in the namespace cattle-monitoring-system</p>
<p>原因: 需要为该用户在cattle-monitoring-system ns中授权 services&#x2F;proxy权限, 同时该用户所对应的角色需要继承 project-monitoring-view角色，这样非admin用户才能看到metrics菜单</p>
<p>参考: <a target="_blank" rel="noopener" href="https://forums.rancher.com/t/cluster-member-cant-see-use-grafana-or-monitoring-stuff/15814">https://forums.rancher.com/t/cluster-member-cant-see-use-grafana-or-monitoring-stuff/15814</a></p>
<h3 id="pod状态提示UnexpectedAdmissionError"><a href="#pod状态提示UnexpectedAdmissionError" class="headerlink" title="pod状态提示UnexpectedAdmissionError"></a>pod状态提示UnexpectedAdmissionError</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20220125180525.png"></p>
<p>原因: 在排查的过程中，发现这个问题涉及的东西太多，写了篇专门的文章来说明这个问题，可参考<a target="_blank" rel="noopener" href="https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError/">Kubernetes-pod-status-is-UnexpectedAdmissionError</a></p>
<h3 id="nvidia-device-plugin-提示bind-address-already-in-use"><a href="#nvidia-device-plugin-提示bind-address-already-in-use" class="headerlink" title="nvidia-device-plugin 提示bind: address already in use"></a>nvidia-device-plugin 提示bind: address already in use</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20220106144313.png"></p>
<p>原因: 这个错误提示其实是有歧义的, 一般看到<code>bind: address already in use</code>都会认为是不是地址端口被占用了, 在这里其实不是，正常来讲<code>nvidia-device-plugin</code>在正常退出后会将节点上的<code>nvidia.sock</code>文件一起删除，启动时会自动创建该文件, 但如果出现退出后<code>nvidia.sock</code>文件还存在，这个时候启动<code>nvidia-device-plugin</code>就会提示上述报错</p>
<p>解决: 手动删除节点上的<code>nvidia.sock</code>,然后重启<code>nvidia-device-plugin</code>即可</p>
<h3 id="prometheus提示-x2F-metrics-x2F-resource-x2F-v1alpha1-404"><a href="#prometheus提示-x2F-metrics-x2F-resource-x2F-v1alpha1-404" class="headerlink" title="prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404"></a>prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20211118152201.png"></p>
<p>原因: 这是因为[&#x2F;metrics&#x2F;resource&#x2F;v1alpha1]是在v1.14中才新增的特性，而当前kubelet版本为1.13</p>
<p>解决: 升级k8s的版本，这里要注意的是<strong>kubelet的版本不能为api-server的高，所以不能只升级kubelet.</strong></p>
<h3 id="Error-from-server-Forbidden-pods-“xxx”-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container"><a href="#Error-from-server-Forbidden-pods-“xxx”-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container" class="headerlink" title="Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container"></a>Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container</h3><p>原因: 排查两个方面，是否有psp，第二个是否启用了相关的admission</p>
<p>解决: 在本case中，因安全因素，开启了DenyEscalatingExec 这个admission，从api-server的配置–enable-admission-plugins中上去掉DenyEscalatingExec 即可</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/</a></p>
<h3 id="kubeadm-join提示unable-to-fetch-the-kubeadm-config-ConfigMap"><a href="#kubeadm-join提示unable-to-fetch-the-kubeadm-config-ConfigMap" class="headerlink" title="kubeadm join提示unable to fetch the kubeadm-config ConfigMap"></a>kubeadm join提示unable to fetch the kubeadm-config ConfigMap</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">discovery</span>] <span class="string">Successfully</span> <span class="string">established</span> <span class="string">connection</span> <span class="string">with</span> <span class="string">API</span> <span class="string">Server</span> <span class="string">&quot;xxx.xxx.xxx.xxx:16443&quot;</span></span><br><span class="line">[<span class="string">join</span>] <span class="string">Reading</span> <span class="string">configuration</span> <span class="string">from</span> <span class="string">the</span> <span class="string">cluster...</span></span><br><span class="line">[<span class="string">join</span>] <span class="attr">FYI:</span> <span class="string">You</span> <span class="string">can</span> <span class="string">look</span> <span class="string">at</span> <span class="string">this</span> <span class="string">config</span> <span class="string">file</span> <span class="string">with</span> <span class="string">&#x27;kubectl -n kube-system get cm kubeadm-config -oyaml&#x27;</span></span><br><span class="line"><span class="attr">unable to fetch the kubeadm-config ConfigMap: failed to get config map: Get https://127.0.0.1:16443/api/v1/namespaces/kube-system/configmaps/kubeadm-config: dial tcp 127.0.0.1:16443: connect:</span> <span class="string">connection</span> <span class="string">refused</span></span><br></pre></td></tr></table></figure>

<p>原因: 127.0.0.1:16443是apiserver的VIP,从报错信息来看, 对127.0.0.1:16443的访问被拒绝了, 但是在apiserver本地curl这个地址又是没问题的，还是非常诡异，可以通过以下方式解决了</p>
<p>解决: 请确认好kubeadm join时会访问的两个配置文件中的apiserver地址是否正确</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get cm kubeadm-config -oyaml</span><br><span class="line"><span class="comment"># 其中的controlPlaneEndpoint地址</span></span><br><span class="line"></span><br><span class="line">kubectl edit cm cluster-info -oyaml -n kube-public</span><br><span class="line"><span class="comment"># 其中的server地址</span></span><br></pre></td></tr></table></figure>

<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubeadm/issues/1596">https://github.com/kubernetes/kubeadm/issues/1596</a></p>
<h3 id="CRD-spec-versions-Invalid-value"><a href="#CRD-spec-versions-Invalid-value" class="headerlink" title="CRD spec.versions: Invalid value"></a>CRD spec.versions: Invalid value</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210622102036.png"></p>
<p>原因: CRD yaml文件中apiVersion与versions中的版本不对应</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/">https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/</a></p>
<h3 id="删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象"><a href="#删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象" class="headerlink" title="删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象"></a>删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210428190009.png"></p>
<p>原因: ns处于terminating时hang住了，使用<code>--grace-period=0 -- force</code>强制删除也无效</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存现在的ns json</span></span><br><span class="line">kubectl get ns xxxx -o json &gt; /tmp/temp.json</span><br><span class="line"><span class="comment"># 编辑temp.json，将其中的spec.finalizer字段删除保存</span></span><br><span class="line"><span class="comment"># 导出k8s访问密钥</span></span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep client-cert  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6) |<span class="built_in">base64</span> -d &gt; /tmp/client.pem</span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep client-key-data  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6 ) |<span class="built_in">base64</span> -d &gt; /tmp/client-key.pem</span><br><span class="line"><span class="built_in">echo</span> $(kubectl config view --raw -oyaml | grep certificate-authority-data  |<span class="built_in">cut</span> -d <span class="string">&#x27; &#x27;</span> -f 6  ) |<span class="built_in">base64</span> -d &gt; /tmp/ca.pem</span><br><span class="line"><span class="comment"># 解决namespace Terminating，根据实际情况修改&lt;namespaces&gt;</span></span><br><span class="line">curl --cert /tmp/client.pem --key /tmp/client-key.pem --cacert /tmp/ca.pem -H <span class="string">&quot;Content-Type: application/json&quot;</span> -X PUT --data-binary @/tmp/temp.json https://xxx.xxx.xxx.xxx:6443/api/v1/namespaces/&lt;namespaces&gt;/finalize</span><br></pre></td></tr></table></figure>

<h3 id="docker-启动时提示no-sockets-found-via-socket-activation"><a href="#docker-启动时提示no-sockets-found-via-socket-activation" class="headerlink" title="docker 启动时提示no sockets found via socket activation"></a>docker 启动时提示no sockets found via socket activation</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210307212429.png"></p>
<p>解决: 在start docker前先执行<code>systemctl unmask docker.socket</code>即可</p>
<h3 id="Prometheus-opening-storage-failed-invalid-block-sequence"><a href="#Prometheus-opening-storage-failed-invalid-block-sequence" class="headerlink" title="Prometheus opening storage failed: invalid block sequence"></a>Prometheus opening storage failed: invalid block sequence</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/image-20210302200255132.png"></p>
<p>原因: 这个需要排查prometheus持久化目录中是否存在时间超出设置阈值的时间段的文件，删掉后重启即可</p>
<h3 id="kubelet提示-The-node-was-low-on-resource-ephemeral-storage"><a href="#kubelet提示-The-node-was-low-on-resource-ephemeral-storage" class="headerlink" title="kubelet提示: The node was low on resource: ephemeral-storage"></a>kubelet提示: The node was low on resource: ephemeral-storage</h3><p>原因: 节点上kubelet的配置路径超过阈值会触发驱逐，默认情况下阈值是85%</p>
<p>解决: 或者清理磁盘释放资源，或者通过可修改kubelet的配置参数<code>imagefs.available</code>来提高阈值,然后重启kubelet.</p>
<p>参考: <a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1456389">https://cloud.tencent.com/developer/article/1456389</a></p>
<h3 id="kubectl查看日志时提示-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout"><a href="#kubectl查看日志时提示-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout" class="headerlink" title="kubectl查看日志时提示: Error from server: Get https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx: dial tcp xxx:10250: i&#x2F;o timeout"></a>kubectl查看日志时提示: Error from server: Get <a target="_blank" rel="noopener" href="https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx">https://xxx:10250/containerLogs/spring-prod/xxx-0/xxx</a>: dial tcp xxx:10250: i&#x2F;o timeout</h3><p>原因: 目地机器的iptables对10250这个端口进行了drop，如下图</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables-save -L INPUT –-line-numbers</span><br></pre></td></tr></table></figure>

<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20210106185555.png"></p>
<p>解决: 删除对应的规则 </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -D INPUT 10</span><br></pre></td></tr></table></figure>

<h3 id="Service解析提示-Temporary-failure-in-name-resolution"><a href="#Service解析提示-Temporary-failure-in-name-resolution" class="headerlink" title="Service解析提示 Temporary failure in name resolution"></a>Service解析提示 Temporary failure in name resolution</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201223232538.png"></p>
<p>原因: 出现这种情况很奇怪，现象显示就是域名无法解析，全格式的域名能够解析是因为在pod的&#x2F;etc&#x2F;hosts中有全域名的记录,那么问题就出在于corddns解析上，coredns从日志来看，没有任何报错，但是从pod的状态来看，虽然处于Running状态，但是0&#x2F;1可以看出coredns并未处于ready状态.</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201223233150.png"></p>
<p>可以查看ep记录，会发现endpoint那一栏是空的，这也就证实了k8s把coredns的状态分为了notready状态，所以ep才没有记录，经过与其它环境比较后发现跟配置有关，最终定位在coredns的配置文件上,在插件上需要加上ready</p>
<p>解决: 在cm的配置上添加read插件，如下图</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ... 省略</span></span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health</span><br><span class="line">        ready  <span class="comment"># 加上该行后问题解决</span></span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          pods insecure</span><br><span class="line">          upstream /etc/resolv.conf</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">       <span class="comment"># ... 省略</span></span><br></pre></td></tr></table></figure>

<p>关于coredns的ready插件的使用,可以参考<a target="_blank" rel="noopener" href="https://coredns.io/plugins/ready/">这里</a></p>
<p>总结起来就是使用ready来表明当前已准备好可以接收请求，从codedns的yaml文件也可以看到有<code>livenessProbe</code></p>
<h3 id="使用Kubectl命令行时提示-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0"><a href="#使用Kubectl命令行时提示-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0" class="headerlink" title="使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0"></a>使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0</h3><p>原因: 这个跟本地的go环境有关</p>
<p>解决: 在使用kubectl前使用命令<code>export GODEBUG=x509ignoreCN=0</code>即可</p>
<h3 id="namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted"><a href="#namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted" class="headerlink" title="namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted"></a>namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted</h3><p>原因: kube-system是集群中受保护的ns, 被禁止删除，主要是防止误操作，如果需要删除的话，可以使用–force</p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/62167/files">https://github.com/kubernetes/kubernetes/pull/62167/files</a></p>
<h3 id="unknown-field-volumeClaimTemplates"><a href="#unknown-field-volumeClaimTemplates" class="headerlink" title="unknown field volumeClaimTemplates"></a>unknown field volumeClaimTemplates</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201112171302.png"></p>
<p>原因: 提示这个错误的原因是资源对象是deployment, 而deployment本就是无状态的， 所以也就没有使用pv这一说法了，可以参考api</p>
<p>参考: <a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps">deploymentspec-v1-apps</a></p>
<h3 id="CoreDNS提示Loop-127-0-0-1-38827-gt-53-detected-for-zone-“-”"><a href="#CoreDNS提示Loop-127-0-0-1-38827-gt-53-detected-for-zone-“-”" class="headerlink" title="CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”"></a>CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20201017221807.png"></p>
<p>原因: CoreDNS所在的宿主机上<code>/etc/resolv.conf</code>中存在有127.0.xx的nameserver,这样会造成解析死循环.</p>
<p>解决: 修改宿主机<code>/etc/resolv.conf</code>或者将CoreDNS的configmap中的forward修改为一个可用的地址, 如<code>8.8.8.8</code></p>
<h3 id="hostPath-volumes-are-not-allowed-to-be-used"><a href="#hostPath-volumes-are-not-allowed-to-be-used" class="headerlink" title="hostPath volumes are not allowed to be used"></a>hostPath volumes are not allowed to be used</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200909154834.png"></p>
<p>原因: 集群中存在psp禁止pod直接挂载hostpath.</p>
<p>解决: 通过添加以下的psp规则来允许或者删除存在的psp都可</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodSecurityPolicy</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">auth-privilege-psp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">allowPrivilegeEscalation:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">allowedHostPaths:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">pathPrefix:</span> <span class="string">/</span></span><br><span class="line">  <span class="attr">fsGroup:</span></span><br><span class="line">    <span class="attr">ranges:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">      <span class="attr">min:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPorts:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">9796</span></span><br><span class="line">    <span class="attr">min:</span> <span class="number">9796</span></span><br><span class="line">  <span class="attr">privileged:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">requiredDropCapabilities:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ALL</span></span><br><span class="line">  <span class="attr">runAsUser:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">seLinux:</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">supplementalGroups:</span></span><br><span class="line">    <span class="attr">ranges:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">max:</span> <span class="number">65535</span></span><br><span class="line">      <span class="attr">min:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">rule:</span> <span class="string">RunAsAny</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">configMap</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">emptyDir</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">projected</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">secret</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">downwardAPI</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">persistentVolumeClaim</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">hostPath</span></span><br></pre></td></tr></table></figure>

<h3 id="container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root"><a href="#container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root" class="headerlink" title="container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root"></a>container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200908211841.png"></p>
<p>原因: 这是由于在deploy中设置了<code>securityContext: runAsNonRoot: true</code>, 在这种情况下，当pod启动时，使用的默认用户,比如上面的grafana，k8s无法确定他是不是root用户</p>
<p>解决: 指定<code>securityContext:runAsUser: 1000</code>, 随便一个id号即可, 只要不是0(0代表root)</p>
<p>参考: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/51544003/using-runasnonroot-in-kubernetes">https://stackoverflow.com/questions/51544003/using-runasnonroot-in-kubernetes</a></p>
<h3 id="OCI-runtime-create-failed-no-such-file-or-directory"><a href="#OCI-runtime-create-failed-no-such-file-or-directory" class="headerlink" title="OCI runtime create failed: no such file or directory"></a>OCI runtime create failed: no such file or directory</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902132758.png"></p>
<p>原因: &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pod下的数据目录已经损坏.</p>
<p>解决: 删除对应的目录即可</p>
<h3 id="镜像拉取时出现ImageInspectError"><a href="#镜像拉取时出现ImageInspectError" class="headerlink" title="镜像拉取时出现ImageInspectError"></a>镜像拉取时出现ImageInspectError</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902123531.png"></p>
<p>原因: 这种情况下一般都是镜像损坏了</p>
<p>解决: 把相关的镜像删除后重新拉取</p>
<h3 id="kubelet日志提示-node-not-found"><a href="#kubelet日志提示-node-not-found" class="headerlink" title="kubelet日志提示: node not found"></a>kubelet日志提示: node not found</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200901183122.png"></p>
<p>原因: 这个报错只是中间过程，真正的原因在于apiserver没有启动成功，导致会一直出现这个错误</p>
<p>解决: 排查kubelet与apiserver的连通是否正常</p>
<h3 id="OCI-runtime-create-failed-executable-file-not-found-in-PATH"><a href="#OCI-runtime-create-failed-executable-file-not-found-in-PATH" class="headerlink" title="OCI runtime create failed: executable file not found in PATH"></a>OCI runtime create failed: executable file not found in PATH</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200902101139.png"></p>
<p>原因: 在path中没有nvidia-container-runtime-hook这个二进制文件，可能跟本人删除nvidia显卡驱动有关.</p>
<p>解决: nvidia-container-runtime-hook是docker nvidia的runtime文件，重新安装即可.</p>
<h3 id="Nginx-Ingress-Empty-address"><a href="#Nginx-Ingress-Empty-address" class="headerlink" title="Nginx Ingress Empty address"></a>Nginx Ingress Empty address</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># kubectl get ingress</span></span><br><span class="line">NAME         HOSTS                                       ADDRESS   PORTS   AGE</span><br><span class="line">prometheus   prometheus.1box.com                                   80      31d</span><br></pre></td></tr></table></figure>

<p>会发现address中的ip是空的，而查看生产环境时却是有ip列表的.</p>
<p>原因: 这个其实不是一个错误，也不影响使用，原因在于测试环境中是不存在LoadBalance类型的svc, 如果需要address中显示ip的话需要做些额外的设置</p>
<p>解决: </p>
<ol>
<li>在nginx controller的容器中指定启动参数<code>-report-ingress-status</code></li>
<li>在nginx controller引用的configmap中添加<code>external-status-address: &quot;10.164.15.220&quot;</code></li>
</ol>
<p>这样的话,在address中变会显示<code>10.164.15.220</code>了</p>
<p>参考:</p>
<p><a target="_blank" rel="noopener" href="https://github.com/nginxinc/kubernetes-ingress/issues/587">https://github.com/nginxinc/kubernetes-ingress/issues/587</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/reporting-resources-status/">https://docs.nginx.com/nginx-ingress-controller/configuration/global-configuration/reporting-resources-status/</a></p>
<h3 id="kubelet-but-volume-paths-are-still-present-on-disk"><a href="#kubelet-but-volume-paths-are-still-present-on-disk" class="headerlink" title="kubelet: but volume paths are still present on disk"></a>kubelet: but volume paths are still present on disk</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200827183609.png"></p>
<p>原因: 这种pod已经被删除了，但是volume还存在于disk中</p>
<p>解决: 删除对应的目录<code>/var/lib/kubelet/pods/3cd73...</code></p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/longhorn/longhorn/issues/485">https://github.com/longhorn/longhorn/issues/485</a></p>
<h3 id="PLEG-is-not-healthy"><a href="#PLEG-is-not-healthy" class="headerlink" title="PLEG is not healthy"></a>PLEG is not healthy</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200827184435.png"></p>
<p>原因: 宿主机上面跑的容器太多，导致pod无法在3m钟内完成生命周期检查</p>
<p>解决:  PLEG(Pod Lifecycle Event Generator)用于kublet同步pod生命周期，本想着如果是因为时间短导致的超时，那是不是可以直接调整这个时间呢? 查看kubelet的源码发现不太行，3m时间是写在代码里的因此无法修改，当然修改再编译肯定没问题，但成本太大，所以只得优化容器的调度情况.</p>
<p>参考: <a target="_blank" rel="noopener" href="https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/">https://developers.redhat.com/blog/2019/11/13/pod-lifecycle-event-generator-understanding-the-pleg-is-not-healthy-issue-in-kubernetes/</a></p>
<h3 id="metrics-server-10255-connection-refused"><a href="#metrics-server-10255-connection-refused" class="headerlink" title="metrics-server: 10255 connection refused"></a>metrics-server: 10255 connection refused</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">unable to fully collect metrics:</span> [<span class="attr">unable to fully scrape metrics from source kubelet_summary:k8s-node-49:</span> <span class="string">unable</span> <span class="string">to</span> <span class="string">fetch</span> <span class="string">metrics</span> <span class="string">from</span> <span class="string">Kubelet</span> <span class="string">k8s-node-49</span> <span class="string">(xxx.xxx.xxx.49):</span> <span class="string">Get</span> <span class="string">http://xxx.xxx.xxx.49:10255/stats/summary?only_cpu_and_memory=true:</span> <span class="attr">dial tcp xxx.xxx.xxx.49:10255: connect:</span> <span class="string">connection</span> <span class="string">refused</span></span><br></pre></td></tr></table></figure>

<p>原因: 现在的k8s都默认禁用了kubelet的10255端口，出现这个错误是因此在kubelet启动命令中启用了该端口</p>
<p>解决: 将<code>- --kubelet-port=10255</code>注释</p>
<h3 id="metrics-server-no-such-host"><a href="#metrics-server-no-such-host" class="headerlink" title="metrics-server: no such host"></a>metrics-server: no such host</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">unable</span> <span class="string">to</span> <span class="string">fetch</span> <span class="string">metrics</span> <span class="string">from</span> <span class="string">Kubelet</span> <span class="string">k8s-node-234</span> <span class="string">(k8s-node-234):</span> <span class="string">Get</span> <span class="string">https://k8s-node-234:10250/stats/summary?only_cpu_and_memory=true:</span> <span class="attr">dial tcp: lookup k8s-node-234 on 10.96.0.10:53:</span> <span class="literal">no</span> <span class="string">such</span> <span class="string">host</span></span><br></pre></td></tr></table></figure>

<p>解决: 使用<code>kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</code>参数</p>
<p>参考: <a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md">https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md</a></p>
<h3 id="pod无法解析域名"><a href="#pod无法解析域名" class="headerlink" title="pod无法解析域名"></a>pod无法解析域名</h3><p>集群中新增了几台机器用于部署clickhouse用于做大数据分析，为了不让这类占用大量资源的Pod影响其它Pod，因此选择给机器打taint的形式控制该类Pod的调度, 创建Pod后发现这些Pod都会出现DNS解析异常, </p>
<p>原因； 要注意容器网络，比如这里使用的是flannel是否容忍了这些机器的taint，不然的话，flannel是无法被调度到这些机器的,因此容器间的通信会出现问题，<strong>可以将类似flannel这些的基础POD容忍所有的NoScheule与NoExecute</strong></p>
<p>解决: flannel的ds yaml中添加以下toleration，这样适用任何的场景</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">Exists</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">effect:</span> <span class="string">NoExecute</span></span><br><span class="line">  <span class="attr">operator:</span> <span class="string">Exists</span></span><br></pre></td></tr></table></figure>

<h3 id="Are-you-tring-to-mount-a-directory-on-to-a-file"><a href="#Are-you-tring-to-mount-a-directory-on-to-a-file" class="headerlink" title="Are you tring to mount a directory on to a file"></a>Are you tring to mount a directory on to a file</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430132115.png"></p>
<p>原因:  Yaml文件中使用了subPath, 但是mountPath指向了一个目录</p>
<p>解决: mountPath需要加上文件名</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430132148.png"></p>
<h3 id="Kubernetes启动后提示slice-no-such-file-ro-directory"><a href="#Kubernetes启动后提示slice-no-such-file-ro-directory" class="headerlink" title="Kubernetes启动后提示slice: no such file ro directory"></a>Kubernetes启动后提示slice: no such file ro directory</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/41B2684F-312C-41ED-AF56-D6014C6B74E6.png"></p>
<p>原因: yum安装的kubelet默认的是cgroupfs，而docker一般默认的是systemd。但是kubernetes安装的时候建议使用systemd, kubelet跟docker的不一致, 要么修改kubelet的启动参数 , 要么修改dokcer启动参数</p>
<p>解决: </p>
<p>docker的启动参数文件为: <code>/etc/docker/daemon.json: &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd”]</code></p>
<p>kubelet的启动参数文件为: <code>/var/lib/kubelet/config.yaml:  cgroupDriver: systemd</code></p>
<h3 id="“cni0”-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx"><a href="#“cni0”-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx" class="headerlink" title="“cni0” already has an IP address different from xxx.xxxx.xxx.xxx"></a>“cni0” already has an IP address different from xxx.xxxx.xxx.xxx</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200430145913.png"></p>
<p>原因: 使用kubeadm reset 重复操作过, reset之后，之前flannel创建的bridge device cni0和网口设备flannel.1依然健在</p>
<p> 解决: 添加之前需要清除下网络</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kubeadm reset</span><br><span class="line">systemctl stop kubelet</span><br><span class="line">systemctl stop docker</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/cni/</span><br><span class="line"><span class="built_in">rm</span> -rf /var/lib/kubelet/*</span><br><span class="line"><span class="built_in">rm</span> -rf /etc/cni/</span><br><span class="line">ifconfig cni0 down</span><br><span class="line">ifconfig flannel.1 down</span><br><span class="line">ifconfig docker0 down</span><br><span class="line">ip <span class="built_in">link</span> delete cni0</span><br><span class="line">ip <span class="built_in">link</span> delete flannel.1</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl start kubelet</span><br></pre></td></tr></table></figure>

<h3 id="kubeadm初始化时提示-CPU小于2"><a href="#kubeadm初始化时提示-CPU小于2" class="headerlink" title="kubeadm初始化时提示 CPU小于2"></a>kubeadm初始化时提示 CPU小于2</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">    [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br></pre></td></tr></table></figure>

<p>原因: kubeadm对资源一定的要求，如果是测试环境无所谓的话,可忽略</p>
<p>解决:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">使用 --ignore-preflight-errors 忽略</span><br></pre></td></tr></table></figure>

<h3 id="Unable-to-update-cni-config-no-network-found"><a href="#Unable-to-update-cni-config-no-network-found" class="headerlink" title="Unable to update cni config: no network found"></a>Unable to update cni config: no network found</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/63611F8A-F803-46F5-8792-67111E03DF91.png"></p>
<p>原因: 还未部署网络插件容器，导致在&#x2F;etc&#x2F;cni下还没有文件</p>
<p>解决: 根据实际情况部署网络插件</p>
<h3 id="while-reading-‘google-dockercfg’-metadata"><a href="#while-reading-‘google-dockercfg’-metadata" class="headerlink" title="while reading ‘google-dockercfg’ metadata"></a>while reading ‘google-dockercfg’ metadata</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/FB66ABBE-FF79-48A4-8A8B-7FDC3AED6634.png"></p>
<p>原因: 从其它机器访问上述这些url确实出现 404</p>
<p>解决: 由于是在RKE上部署k8s, 所以可能会去访问google相关的url, 不影响业务,可以忽略</p>
<h3 id="no-providers-available-to-validate-pod-request"><a href="#no-providers-available-to-validate-pod-request" class="headerlink" title="no providers available to validate pod request"></a>no providers available to validate pod request</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/ACEB6BE6-7E22-4A43-AB4A-A51E00CE9EFE.png"></p>
<p>原因: 在api-server的启动参数enable-admission中设置了PodSecrityPolicy, 但是集群中又没有任何的podsecritypolicy，因此导致整个集群都无法新建出pod</p>
<p>解决: 删除相应的podsecritypolicy即可</p>
<h3 id="unable-to-upgrade-connection-Unauthorized"><a href="#unable-to-upgrade-connection-Unauthorized" class="headerlink" title="unable to upgrade connection: Unauthorized"></a>unable to upgrade connection: Unauthorized</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/5FECFF57-F204-4ADF-A9E0-5F1D9A917194.png"></p>
<p>原因: kubelet的启动参数少了x509认证方式</p>
<p>解决: 配置证书的路径, 加上重启kubelet即可</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/447313AF-7DD6-4FB4-8F46-AE1DC468C7CA.png"></p>
<h3 id="kubectl-get-cs-提示-lt-unknown-gt"><a href="#kubectl-get-cs-提示-lt-unknown-gt" class="headerlink" title="kubectl get cs 提示&lt;unknown&gt;"></a>kubectl get cs 提示&lt;unknown&gt;</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/C73EB07F-14CD-43A7-86C0-49B4812F57A6.png"></p>
<p>原因: 这是个kubectl的bug, 跟版本相关，kubernetes有意废除get cs命令</p>
<p>解决: 目前对集群的运行无影响, 可通过加-oyaml 查看状态</p>
<h3 id="安装kubeadm时提示Depends错误"><a href="#安装kubeadm时提示Depends错误" class="headerlink" title="安装kubeadm时提示Depends错误"></a>安装kubeadm时提示Depends错误</h3><p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/2AE46262-2624-446C-909E-1FA0E76A8AD7.png"></p>
<p>原因:  跟kubeadm没多大关系, 系统安装的有问题</p>
<p>解决: 执行以下命令修复</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">apt --fix-broken install </span><br><span class="line">apt-get update</span><br></pre></td></tr></table></figure>

<h3 id="访问service时提示Connection-refused"><a href="#访问service时提示Connection-refused" class="headerlink" title="访问service时提示Connection refused"></a>访问service时提示Connection refused</h3><p>现象: 从另一环境中把yaml文件导入到新环境后有些service访问不通</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">telnet mongodb-mst.external 27017</span><br><span class="line">Trying 10.97.135.242...</span><br><span class="line">telnet: Unable to connect to remote host: Connection refused</span><br></pre></td></tr></table></figure>

<p>首先排除了域名、端口的配置问题。</p>
<p>会发现提示连接拒绝.可以确定的是集群内的DNS是正常的.</p>
<p>那么就是通过clusterIP无法到达realserver. 查看iptables规则</p>
<p>发现提示<code>default has no endpoints --reject-with icmp-port-unreachable</code></p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506115705.png"></p>
<p>很奇怪, 提示没有endpoints, 但是使用<code>kubectl get ep</code>又能看到ep存在且配置没有问题</p>
<p>而且这个default是怎么来的.</p>
<p>为了方便部署, 很多配置是从别的环境导出的配置, 有些service访问是没问题的, 只有少部分<code>connection refused</code></p>
<p>结比一下发现一个很有趣的问题，先来看下不正常的yaml文件:</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506115805.png"></p>
<p>由于服务在集群外部署的, 因此这里使用了subset方式, 开始怀疑问题在这里, 但是后来知道这个不是重点</p>
<p>乍一看这个配置没什么问题, 部署也很正常, 但是对比正常的yaml文件，发现一个区别：</p>
<p>如果在services中的端口指定了名字, 那么在subsets中的端口也要带名字, 没有带名字的就会出现<code>connection refused</code>，这个确实之前从来没有关注过, 一个端口的情况下也不会指定名字</p>
<p>而且这面iptalbes中提示的default刚好就是这里的port name,虽然不敢相信，但是也只能试一试这个方法: 在subsets中也加了port name</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506120151.png"></p>
<p>重新部署一个，再次查看iptalbes规则 </p>
<p><code>iptables-save|grep mongodb-mst</code></p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200506120040.png"></p>
<p>OMG, 居然可行, 再看下telnet的结果:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Trying 10.105.116.92...</span><br><span class="line">Connected to mongodb-mst.external.svc.cluster.local.</span><br><span class="line">Escape character is <span class="string">&#x27;^]&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>访问也是没问题, 那么原因就在于:</p>
<p><strong>在service中指定了port name时, 也需要在ep中指定port name</strong></p>
<h3 id="error-converting-fieldPath-field-label-not-supported"><a href="#error-converting-fieldPath-field-label-not-supported" class="headerlink" title="error converting fieldPath: field label not supported"></a>error converting fieldPath: field label not supported</h3><p>今天遇到一个部署deployment出错的问题, yaml文件如下:</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demo-deployment</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">4test</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">config-demo-app</span></span><br><span class="line">      <span class="attr">annotations:</span></span><br><span class="line">        <span class="comment"># The field we&#x27;ll use to couple our ConfigMap and Deployment</span></span><br><span class="line">        <span class="attr">configHash:</span> <span class="string">4431f6d28fdf60c8140d28c42cde331a76269ac7a0e6af01d0de0fa8392c1145</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-demo-app</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">gcr.io/optimum-rock-145719/config-demo-app</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">envFrom:</span></span><br><span class="line">        <span class="comment"># The ConfigMap we want to use</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">configMapRef:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">demo-config</span></span><br><span class="line">        <span class="comment"># Extra-curricular: We can make the hash of our ConfigMap available at a</span></span><br><span class="line">        <span class="comment"># (e.g.) debug endpoint via a fieldRef</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CONFIG_HASH</span></span><br><span class="line">          <span class="comment">#value: &quot;4431f6d28fdf60c8140d28c42cde331a76269ac7a0e6af01d0de0fa8392c1145&quot;</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">fieldRef:</span></span><br><span class="line">              <span class="attr">fieldPath:</span> <span class="string">spec.template.metadata.annotations.configHash</span></span><br></pre></td></tr></table></figure>

<p>提示以下错误:</p>
<p><img src="https://raw.githubusercontent.com/zhoushuke/BlogPhoto/master/githuboss/20200511180743.png"></p>
<p>会提示<code>Unsupported value:spec.template.metadata.annotations.configHash</code></p>
<p>目的很简单: container中的环境变量中引用configHash变量, 这个值是当configmap变更时比对两个不同的sha值以此达到重启pod的目的, 但fieldPath显然不支持<code>spec.template.metadata.annotations.configHash</code></p>
<p>从报错提示来看, 支持列表有<code>metadata.name, metadata.namespace, metadata.uid, spec.nodeName,spec.serviceAccountName, status.hostIp, status.PodIP, status.PodIPs</code></p>
<p>这些值用于容器中需要以下信息时可以不从k8s的apiserver中获取而是可以很方便地从这些变量直接获得</p>
<p>参考: </p>
<p><a target="_blank" rel="noopener" href="https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern">https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern</a></p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/</a></p>
<h3 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章:"></a><strong>参考文章:</strong></h3><blockquote>
<ul>
<li><a target="_blank" rel="noopener" href="https://izsk.me/2024/08/10/cilium-on-kubernetes-errors-apiratelimit/">cilium在kubernetes中的生产实践六(cilium排错指南)之api-rate-limit</a></li>
<li><a target="_blank" rel="noopener" href="https://enix.io/fr/blog/kubernetes-tip-and-tricks-node-authorization-mode/">Kubernetes : Le Node Authorization Mode de l&#39;API-Server</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/docs/en/cloud-private/3.2.0?topic=console-namespace-is-stuck-in-terminating-state">https://www.ibm.com/docs/en/cloud-private/3.2.0?topic=console-namespace-is-stuck-in-terminating-state</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/">https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definition-versioning/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/issues/19317">https://github.com/kubernetes/kubernetes/issues/19317</a></li>
<li><a target="_blank" rel="noopener" href="http://www.xuyasong.com/?p=1725">http://www.xuyasong.com/?p=1725</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/">https://kubernetes.io/</a></li>
<li><a target="_blank" rel="noopener" href="https://fuckcloudnative.io/">https://fuckcloudnative.io/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/breezey/p/8810039.html">https://www.cnblogs.com/breezey/p/8810039.html</a></li>
<li><a target="_blank" rel="noopener" href="https://ieevee.com/tech/2018/04/25/downwardapi.html">https://ieevee.com/tech/2018/04/25/downwardapi.html</a></li>
<li><a target="_blank" rel="noopener" href="https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern">https://www.magalix.com/blog/kubernetes-patterns-the-reflection-pattern</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps">https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#deploymentspec-v1-apps</a></li>
<li><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/">https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/pull/62167/files">https://github.com/kubernetes/kubernetes/pull/62167/files</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md">https://github.com/kubernetes-sigs/metrics-server/blob/master/README.md</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubeadm/issues/1596">https://github.com/kubernetes/kubeadm/issues/1596</a></li>
<li><a target="_blank" rel="noopener" href="https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError">https://izsk.me/2022/01/27/Kubernetes-pod-status-is-UnexpectedAdmissionError</a></li>
</ul>
</blockquote>
<h3 id="转载请注明原作者-周淑科-https-izsk-me"><a href="#转载请注明原作者-周淑科-https-izsk-me" class="headerlink" title="转载请注明原作者: 周淑科(https://izsk.me)"></a><strong>转载请注明原作者: 周淑科(<a target="_blank" rel="noopener" href="https://izsk.me/">https://izsk.me</a>)</strong></h3>
      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/images/websitecode250.png" alt=" wechat" style="width: 200px; max-width: 100%;"/>
    <div>Scan Me To Read on Phone</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>I know you won't do this,but what if you did?</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/images/wechatpayme.png" alt=" WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/images/alipayme.jpg" alt=" Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Kubernetes/" rel="tag"># Kubernetes</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2023/11/12/volcano-key-resources/" rel="next" title="volcano如何应对大规模任务系列之volcano关键对象">
                <i class="fa fa-chevron-left"></i> volcano如何应对大规模任务系列之volcano关键对象
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2023/12/14/Kubernetes-listOption-1/" rel="prev" title="Kubernetes之ListOptions使用不当引发的ETCD网络风暴">
                Kubernetes之ListOptions使用不当引发的ETCD网络风暴 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="" />
          <p class="site-author-name" itemprop="name"></p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">213</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%97%A5%E5%BF%97%E9%94%99%E8%AF%AF-Unable-to-create-endpoint-status-429"><span class="nav-number">1.</span> <span class="nav-text">kubelet日志错误: Unable to create endpoint (status 429)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E4%B8%AD%E6%8F%90%E7%A4%BA-no-relationship-found-between-node-xxx-and-this-object"><span class="nav-number">2.</span> <span class="nav-text">kubelet中提示: no relationship found between node xxx and this object</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-controller-manager%E6%97%A5%E5%BF%97%E5%87%BA%E7%8E%B0-unable-to-retrieve-the-complete-list-of-server-APIs-metrics-k8s-io-x2F-v1beta1"><span class="nav-number">3.</span> <span class="nav-text">kube-controller-manager日志出现: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8F%90%E7%A4%BAFailed-to-start-ContainerManager-failed-to-build-map-of-initial-containers-from-runtime-no-PodsandBox-found-with-Id"><span class="nav-number">4.</span> <span class="nav-text">kubelet启动时提示Failed to start ContainerManager failed to build map of initial containers from runtime: no PodsandBox found with Id</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#prometheus-logs-compaction-failed-%E5%AF%B9%E6%95%B0%E7%9A%84%E6%80%A7%E8%B4%A8uption-in-segment-xxxx-at-yyyy-unexpected-non-zero-byte-in-padded-page"><span class="nav-number">5.</span> <span class="nav-text">prometheus logs: compaction failed, 对数的性质uption in segment xxxx at yyyy: unexpected non-zero byte in padded page</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#is-forbidden-User-xxx-cannot-get-resource-%E2%80%9Cservices-x2F-proxy%E2%80%9D"><span class="nav-number">6.</span> <span class="nav-text">is forbidden: User xxx cannot get resource “services&#x2F;proxy”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pod%E7%8A%B6%E6%80%81%E6%8F%90%E7%A4%BAUnexpectedAdmissionError"><span class="nav-number">7.</span> <span class="nav-text">pod状态提示UnexpectedAdmissionError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#nvidia-device-plugin-%E6%8F%90%E7%A4%BAbind-address-already-in-use"><span class="nav-number">8.</span> <span class="nav-text">nvidia-device-plugin 提示bind: address already in use</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#prometheus%E6%8F%90%E7%A4%BA-x2F-metrics-x2F-resource-x2F-v1alpha1-404"><span class="nav-number">9.</span> <span class="nav-text">prometheus提示 &#x2F;metrics&#x2F;resource&#x2F;v1alpha1 404</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Error-from-server-Forbidden-pods-%E2%80%9Cxxx%E2%80%9D-is-forbidden-cannot-exec-into-or-attach-to-a-privileged-container"><span class="nav-number">10.</span> <span class="nav-text">Error from server (Forbidden): pods “xxx” is forbidden: cannot exec into or attach to a privileged container</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubeadm-join%E6%8F%90%E7%A4%BAunable-to-fetch-the-kubeadm-config-ConfigMap"><span class="nav-number">11.</span> <span class="nav-text">kubeadm join提示unable to fetch the kubeadm-config ConfigMap</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CRD-spec-versions-Invalid-value"><span class="nav-number">12.</span> <span class="nav-text">CRD spec.versions: Invalid value</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A0%E9%99%A4namespaces%E6%97%B6Terminating%EF%BC%8C%E6%97%A0%E6%B3%95%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E4%B8%94%E6%97%A0%E6%B3%95%E5%9C%A8%E8%AF%A5ns%E4%B8%8B%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1"><span class="nav-number">13.</span> <span class="nav-text">删除namespaces时Terminating，无法强制删除且无法在该ns下创建对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#docker-%E5%90%AF%E5%8A%A8%E6%97%B6%E6%8F%90%E7%A4%BAno-sockets-found-via-socket-activation"><span class="nav-number">14.</span> <span class="nav-text">docker 启动时提示no sockets found via socket activation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prometheus-opening-storage-failed-invalid-block-sequence"><span class="nav-number">15.</span> <span class="nav-text">Prometheus opening storage failed: invalid block sequence</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%8F%90%E7%A4%BA-The-node-was-low-on-resource-ephemeral-storage"><span class="nav-number">16.</span> <span class="nav-text">kubelet提示: The node was low on resource: ephemeral-storage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubectl%E6%9F%A5%E7%9C%8B%E6%97%A5%E5%BF%97%E6%97%B6%E6%8F%90%E7%A4%BA-Error-from-server-Get-https-xxx-10250-containerLogs-spring-prod-xxx-0-xxx-dial-tcp-xxx-10250-i-x2F-o-timeout"><span class="nav-number">17.</span> <span class="nav-text">kubectl查看日志时提示: Error from server: Get https:&#x2F;&#x2F;xxx:10250&#x2F;containerLogs&#x2F;spring-prod&#x2F;xxx-0&#x2F;xxx: dial tcp xxx:10250: i&#x2F;o timeout</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service%E8%A7%A3%E6%9E%90%E6%8F%90%E7%A4%BA-Temporary-failure-in-name-resolution"><span class="nav-number">18.</span> <span class="nav-text">Service解析提示 Temporary failure in name resolution</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8Kubectl%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%97%B6%E6%8F%90%E7%A4%BA-Unable-to-connect-to-the-server-x509-certificate-relies-on-legacy-Common-Name-field-use-SANs-or-temporarily-enable-Common-Name-matching-with-GODEBUG-x3D-x509ignoreCN-x3D-0"><span class="nav-number">19.</span> <span class="nav-text">使用Kubectl命令行时提示: Unable to connect to the server: x509: certificate relies on legacy Common Name field, use SANs or temporarily enable Common Name matching with GODEBUG&#x3D;x509ignoreCN&#x3D;0</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#namespaces-quot-kube-system-quot-is-forbidden-this-namespace-may-not-be-deleted"><span class="nav-number">20.</span> <span class="nav-text">namespaces &quot;kube-system&quot; is forbidden: this namespace may not be deleted</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unknown-field-volumeClaimTemplates"><span class="nav-number">21.</span> <span class="nav-text">unknown field volumeClaimTemplates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CoreDNS%E6%8F%90%E7%A4%BALoop-127-0-0-1-38827-gt-53-detected-for-zone-%E2%80%9C-%E2%80%9D"><span class="nav-number">22.</span> <span class="nav-text">CoreDNS提示Loop (127.0.0.1:38827 -&gt; :53) detected for zone “.”</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hostPath-volumes-are-not-allowed-to-be-used"><span class="nav-number">23.</span> <span class="nav-text">hostPath volumes are not allowed to be used</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#container-has-runAsNonRoot-and-image-has-non-numeric-user-grafana-cannot-verify-user-is-non-root"><span class="nav-number">24.</span> <span class="nav-text">container has runAsNonRoot and image has non-numeric user (grafana), cannot verify user is non-root</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OCI-runtime-create-failed-no-such-file-or-directory"><span class="nav-number">25.</span> <span class="nav-text">OCI runtime create failed: no such file or directory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%95%9C%E5%83%8F%E6%8B%89%E5%8F%96%E6%97%B6%E5%87%BA%E7%8E%B0ImageInspectError"><span class="nav-number">26.</span> <span class="nav-text">镜像拉取时出现ImageInspectError</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet%E6%97%A5%E5%BF%97%E6%8F%90%E7%A4%BA-node-not-found"><span class="nav-number">27.</span> <span class="nav-text">kubelet日志提示: node not found</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OCI-runtime-create-failed-executable-file-not-found-in-PATH"><span class="nav-number">28.</span> <span class="nav-text">OCI runtime create failed: executable file not found in PATH</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Nginx-Ingress-Empty-address"><span class="nav-number">29.</span> <span class="nav-text">Nginx Ingress Empty address</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet-but-volume-paths-are-still-present-on-disk"><span class="nav-number">30.</span> <span class="nav-text">kubelet: but volume paths are still present on disk</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PLEG-is-not-healthy"><span class="nav-number">31.</span> <span class="nav-text">PLEG is not healthy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metrics-server-10255-connection-refused"><span class="nav-number">32.</span> <span class="nav-text">metrics-server: 10255 connection refused</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#metrics-server-no-such-host"><span class="nav-number">33.</span> <span class="nav-text">metrics-server: no such host</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#pod%E6%97%A0%E6%B3%95%E8%A7%A3%E6%9E%90%E5%9F%9F%E5%90%8D"><span class="nav-number">34.</span> <span class="nav-text">pod无法解析域名</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Are-you-tring-to-mount-a-directory-on-to-a-file"><span class="nav-number">35.</span> <span class="nav-text">Are you tring to mount a directory on to a file</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kubernetes%E5%90%AF%E5%8A%A8%E5%90%8E%E6%8F%90%E7%A4%BAslice-no-such-file-ro-directory"><span class="nav-number">36.</span> <span class="nav-text">Kubernetes启动后提示slice: no such file ro directory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%9Ccni0%E2%80%9D-already-has-an-IP-address-different-from-xxx-xxxx-xxx-xxx"><span class="nav-number">37.</span> <span class="nav-text">“cni0” already has an IP address different from xxx.xxxx.xxx.xxx</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubeadm%E5%88%9D%E5%A7%8B%E5%8C%96%E6%97%B6%E6%8F%90%E7%A4%BA-CPU%E5%B0%8F%E4%BA%8E2"><span class="nav-number">38.</span> <span class="nav-text">kubeadm初始化时提示 CPU小于2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Unable-to-update-cni-config-no-network-found"><span class="nav-number">39.</span> <span class="nav-text">Unable to update cni config: no network found</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#while-reading-%E2%80%98google-dockercfg%E2%80%99-metadata"><span class="nav-number">40.</span> <span class="nav-text">while reading ‘google-dockercfg’ metadata</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#no-providers-available-to-validate-pod-request"><span class="nav-number">41.</span> <span class="nav-text">no providers available to validate pod request</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#unable-to-upgrade-connection-Unauthorized"><span class="nav-number">42.</span> <span class="nav-text">unable to upgrade connection: Unauthorized</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubectl-get-cs-%E6%8F%90%E7%A4%BA-lt-unknown-gt"><span class="nav-number">43.</span> <span class="nav-text">kubectl get cs 提示&lt;unknown&gt;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%89%E8%A3%85kubeadm%E6%97%B6%E6%8F%90%E7%A4%BADepends%E9%94%99%E8%AF%AF"><span class="nav-number">44.</span> <span class="nav-text">安装kubeadm时提示Depends错误</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%BF%E9%97%AEservice%E6%97%B6%E6%8F%90%E7%A4%BAConnection-refused"><span class="nav-number">45.</span> <span class="nav-text">访问service时提示Connection refused</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#error-converting-fieldPath-field-label-not-supported"><span class="nav-number">46.</span> <span class="nav-text">error converting fieldPath: field label not supported</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0"><span class="nav-number">47.</span> <span class="nav-text">参考文章:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AC%E8%BD%BD%E8%AF%B7%E6%B3%A8%E6%98%8E%E5%8E%9F%E4%BD%9C%E8%80%85-%E5%91%A8%E6%B7%91%E7%A7%91-https-izsk-me"><span class="nav-number">48.</span> <span class="nav-text">转载请注明原作者: 周淑科(https:&#x2F;&#x2F;izsk.me)</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Z.S.K.</span>
</div>


<div class="powered-by">
  Supported by <a class="theme-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" target="_blank" rel="noopener" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  

  


</body>
</html>
